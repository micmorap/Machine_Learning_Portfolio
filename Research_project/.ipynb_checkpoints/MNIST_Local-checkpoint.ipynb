{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a179439-171a-4003-b7c0-f041cc70567a",
   "metadata": {},
   "source": [
    "# Research project - Distributed deep learning with Pythorch\n",
    "\n",
    "## Local version\n",
    "\n",
    "### AI Specialization University Minuto de Dios\n",
    "\n",
    "#### Made by: Michael Andr√©s Mora Poveda\n",
    "\n",
    "Objective:\n",
    "\n",
    "The aim of this notebook is apply convolutional neural networks to train a multiclassifier with MNIST dataset \n",
    "in local version and with Pytorch deep learning framework. Moreover, it's important taking into account that other\n",
    "purpose is calculate the time processing to contrast it with on-cloud distributed version on Azure.\n",
    "\n",
    "All the descriptions and explanations about this dataset could be find in the following url:\n",
    "\n",
    "**https://www.tensorflow.org/datasets/catalog/mnist**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7408adc3-fac1-422c-954b-15ee54c1d6c7",
   "metadata": {},
   "source": [
    "##### 1. Import the respective packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d6553b-5dd4-4150-9503-62d16ef8f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pendulum\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3df373-9571-4b01-9335-1045cd5e39ee",
   "metadata": {},
   "source": [
    "##### 2. Parameterize the transformations to normalize the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aabeb5e-a587-410a-ac8c-ccbb52853473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones y carga del conjunto de entrenamiento\n",
    "def transform_data():\n",
    "    \"\"\"\n",
    "    Apply the Compose function to convert an image to tensor\n",
    "    and normalize the MNIST pictures with mean and standard \n",
    "    deviation equal to 0.5\n",
    "\n",
    "    Args: \n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        Pictures normalized.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e8ddc-9209-4f6c-9a52-6f4b8c464f0d",
   "metadata": {},
   "source": [
    "##### 3. Import the dataset directly from Pytorch dataset module and apply the data loader function to save all the files into data folder and visualize any properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8fc7380-f6b8-4e22-8e8e-a36eb0c04390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_df(batch_size: int):\n",
    "    \"\"\"\n",
    "    Import, save and load the MNIST dataset from Pythorch.datasets module.\n",
    "\n",
    "    Args: \n",
    "        batch_size (int): Number of pictures to each batch.\n",
    "\n",
    "    Returns:\n",
    "        train_loader: Training set \n",
    "        test_loader: Testing set \n",
    "    \"\"\"\n",
    "    train_set = datasets.MNIST(root='./data_source', train = True, transform=transform_data(), download=True)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_set = datasets.MNIST(root='./data_source', train=False, transform=transform_data(), download=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd3159-2d16-4b8d-a064-c24076a7d2cc",
   "metadata": {},
   "source": [
    "##### 4. Define the Net class to instiate the convolutional neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d705f14d-e633-4b98-94ee-ffc5c0602447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor method to our Convolutional Neural Network with Pytorch.\n",
    "\n",
    "        Definitions: \n",
    "        The first layer applied to gray scale pictures has 1 input and 32 outputs\n",
    "        with a 3x3 kernel with a stride equal to 1.\n",
    "\n",
    "        The second layer has 32 inputs (generated by the previous layer) and 64 outputs.\n",
    "\n",
    "        Then, We create two dropouts hidden layers to turn-off certaing neurons and\n",
    "        two layers totally connected, that means, these ones make the mathematical processes.\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function define the architecture of our neural network and\n",
    "        each step to process our pictures:\n",
    "\n",
    "        * Apply the first convolutional layer\n",
    "        * Apply the ReLu activaction function\n",
    "        * Apply the second convolutional layer\n",
    "        * Apply max pooling with a 2x2 kernel\n",
    "        * Apply dropout to turn-off certain neurons \n",
    "        * Create the 1D tensor with Flatten function\n",
    "        * Apply the first dense layer totally connected\n",
    "        * Apply the ReLu activaction function\n",
    "        * Apply dropout to turn-off certain neurons \n",
    "        * Apply the second dense layer totally connected\n",
    "        * Apply the log_softmax function\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor\n",
    "\n",
    "        Return:\n",
    "            The outputs with the logaritmic probabilities.\n",
    "        \n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d27083-3e6c-47e8-9840-2113e39d2123",
   "metadata": {},
   "source": [
    "##### 5. Define the training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840081e2-aeb1-4d87-9d9e-9196e88c49bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(cnn_model, train_loader, criterion, optimizer, epochs):\n",
    "    \"\"\"\n",
    "    This function train our CNN.\n",
    "\n",
    "    Args:\n",
    "        cnn_model (Net): Our CNN model instantiate with Pytorch\n",
    "        train_loader (DataLoader object): Training set normalized\n",
    "        criterion (torch.nn object): Loss function\n",
    "        optimizer(torch.optim object): Optimizer to backpropagation process\n",
    "        epoch (int): Number of epochs to train our model\n",
    "\n",
    "    Return:\n",
    "        Print the results of each training epoch.    \n",
    "    \"\"\"\n",
    "    cnn_model.train()\n",
    "    batch_size = 128\n",
    "    error = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            var_x_batch = x_batch.float()\n",
    "            var_y_batch = y_batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = cnn_model(var_x_batch)\n",
    "            loss = error(outputs, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #Total correct predictions:\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            correct += (predicted == var_y_batch).sum() \n",
    "            \n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f} \\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, \n",
    "                    batch_idx * len(x_batch), \n",
    "                    len(train_loader.dataset),\n",
    "                    100 * batch_idx / len(train_loader), \n",
    "                    loss.item(),\n",
    "                    float(correct*100) / float(len(train_loader.dataset) * (batch_idx +1))\n",
    "                )\n",
    "                         \n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ec196-ba6c-4314-80c8-2257b5964021",
   "metadata": {},
   "source": [
    "##### 6. Define the testing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b26a67-6632-433c-ba29-a12b2d5558c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnn(cnn_model, test_loader):\n",
    "    \"\"\"\n",
    "    This function test our CNN.\n",
    "\n",
    "    Args:\n",
    "        cnn_model (Net): Our CNN model instantiate with Pytorch\n",
    "        test_loader (DataLoader object): Testing set normalized\n",
    "        criterion (torch.nn object): Loss function\n",
    "        epoch (int): Number of epochs to train our model\n",
    "\n",
    "    Return:\n",
    "        Print the performance metrics to each one of our training epochs.       \n",
    "    \"\"\"\n",
    "    batch_size =  128\n",
    "    correct = 0\n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        test_imgs = Variable(test_imgs).float()\n",
    "        output = cnn_model(test_imgs)\n",
    "        predicted = torch.max(output, 1)[1]\n",
    "        correct += (predicted == test_labels).sum()\n",
    "    print(\"Test accuracy:{:.3f}%\".format(float(correct) / (len(test_loader)*batch_size))) \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2025657b-f88c-4bc8-a615-f3b072fbd465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Apply each function defined previously to our CNN model:\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate the datasets and dataloaders:\n",
    "    train_loader, test_loader = load_mnist_df(batch_size = 128)\n",
    "\n",
    "    # Visualize any properties:\n",
    "    data_iter = iter(train_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    num_batches = len(train_loader)\n",
    "    print(\"Total batches to training:\", num_batches)\n",
    "    \n",
    "    # Pictures and label shapes:\n",
    "    print(\"Pictures shape:\", images.shape)\n",
    "    print(\"Labels column shape:\", labels.shape)\n",
    "\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    num_batches = len(test_loader)\n",
    "    print(\"Total batches to testing:\", num_batches)\n",
    "    \n",
    "    # Pictures and label shapes:\n",
    "    print(\"Pictures shape:\", images.shape)\n",
    "    print(\"Labels column shape:\", labels.shape)\n",
    "\n",
    "\n",
    "    # Instantiate the CNN, loss function and optimizer:\n",
    "    cnn_model = Net()\n",
    "    print(cnn_model)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Start time execution:\n",
    "    start_time = pendulum.now()\n",
    "\n",
    "    # Training and testing:\n",
    "    train_cnn(cnn_model, train_loader, criterion, optimizer, epochs = 30)\n",
    "    test_cnn(cnn_model, test_loader)\n",
    "\n",
    "\n",
    "    # Final time execution:\n",
    "    end_time = pendulum.now()\n",
    "    execution_time = (end_time - start_time).in_minutes()\n",
    "    print(f\"Total Execution Time: {execution_time:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86d6715c-b60d-46df-8d26-04a08870816b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to training: 469\n",
      "Pictures shape: torch.Size([128, 1, 28, 28])\n",
      "Labels column shape: torch.Size([128])\n",
      "Total batches to testing: 79\n",
      "Pictures shape: torch.Size([128, 1, 28, 28])\n",
      "Labels column shape: torch.Size([128])\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 0 [0/60000 (0%)]\t Loss: 2.294469 \t Accuracy:0.022%\n",
      "Train Epoch: 0 [6400/60000 (11%)]\t Loss: 0.648573 \t Accuracy:0.121%\n",
      "Train Epoch: 0 [12800/60000 (21%)]\t Loss: 0.465843 \t Accuracy:0.150%\n",
      "Train Epoch: 0 [19200/60000 (32%)]\t Loss: 0.325001 \t Accuracy:0.162%\n",
      "Train Epoch: 0 [25600/60000 (43%)]\t Loss: 0.191936 \t Accuracy:0.170%\n",
      "Train Epoch: 0 [32000/60000 (53%)]\t Loss: 0.325443 \t Accuracy:0.174%\n",
      "Train Epoch: 0 [38400/60000 (64%)]\t Loss: 0.320438 \t Accuracy:0.178%\n",
      "Train Epoch: 0 [44800/60000 (75%)]\t Loss: 0.240330 \t Accuracy:0.180%\n",
      "Train Epoch: 0 [51200/60000 (85%)]\t Loss: 0.240906 \t Accuracy:0.182%\n",
      "Train Epoch: 0 [57600/60000 (96%)]\t Loss: 0.169748 \t Accuracy:0.184%\n",
      "Train Epoch: 1 [0/60000 (0%)]\t Loss: 0.371881 \t Accuracy:0.192%\n",
      "Train Epoch: 1 [6400/60000 (11%)]\t Loss: 0.206504 \t Accuracy:0.198%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\t Loss: 0.146183 \t Accuracy:0.198%\n",
      "Train Epoch: 1 [19200/60000 (32%)]\t Loss: 0.143225 \t Accuracy:0.198%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\t Loss: 0.289160 \t Accuracy:0.198%\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t Loss: 0.296125 \t Accuracy:0.198%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\t Loss: 0.097770 \t Accuracy:0.198%\n",
      "Train Epoch: 1 [44800/60000 (75%)]\t Loss: 0.125205 \t Accuracy:0.199%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\t Loss: 0.197046 \t Accuracy:0.198%\n",
      "Train Epoch: 1 [57600/60000 (96%)]\t Loss: 0.133108 \t Accuracy:0.198%\n",
      "Train Epoch: 2 [0/60000 (0%)]\t Loss: 0.210263 \t Accuracy:0.198%\n",
      "Train Epoch: 2 [6400/60000 (11%)]\t Loss: 0.221220 \t Accuracy:0.198%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\t Loss: 0.153765 \t Accuracy:0.199%\n",
      "Train Epoch: 2 [19200/60000 (32%)]\t Loss: 0.313902 \t Accuracy:0.199%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\t Loss: 0.250261 \t Accuracy:0.199%\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t Loss: 0.234976 \t Accuracy:0.199%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\t Loss: 0.293722 \t Accuracy:0.199%\n",
      "Train Epoch: 2 [44800/60000 (75%)]\t Loss: 0.291514 \t Accuracy:0.199%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\t Loss: 0.173102 \t Accuracy:0.199%\n",
      "Train Epoch: 2 [57600/60000 (96%)]\t Loss: 0.099605 \t Accuracy:0.199%\n",
      "Train Epoch: 3 [0/60000 (0%)]\t Loss: 0.241172 \t Accuracy:0.200%\n",
      "Train Epoch: 3 [6400/60000 (11%)]\t Loss: 0.242552 \t Accuracy:0.200%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\t Loss: 0.249391 \t Accuracy:0.201%\n",
      "Train Epoch: 3 [19200/60000 (32%)]\t Loss: 0.223792 \t Accuracy:0.201%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\t Loss: 0.304383 \t Accuracy:0.200%\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t Loss: 0.150487 \t Accuracy:0.200%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\t Loss: 0.281524 \t Accuracy:0.201%\n",
      "Train Epoch: 3 [44800/60000 (75%)]\t Loss: 0.076493 \t Accuracy:0.201%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\t Loss: 0.206338 \t Accuracy:0.201%\n",
      "Train Epoch: 3 [57600/60000 (96%)]\t Loss: 0.251028 \t Accuracy:0.201%\n",
      "Train Epoch: 4 [0/60000 (0%)]\t Loss: 0.298907 \t Accuracy:0.205%\n",
      "Train Epoch: 4 [6400/60000 (11%)]\t Loss: 0.166458 \t Accuracy:0.202%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\t Loss: 0.301363 \t Accuracy:0.201%\n",
      "Train Epoch: 4 [19200/60000 (32%)]\t Loss: 0.240432 \t Accuracy:0.201%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\t Loss: 0.156832 \t Accuracy:0.201%\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t Loss: 0.180998 \t Accuracy:0.201%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\t Loss: 0.336152 \t Accuracy:0.201%\n",
      "Train Epoch: 4 [44800/60000 (75%)]\t Loss: 0.226505 \t Accuracy:0.201%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\t Loss: 0.212698 \t Accuracy:0.201%\n",
      "Train Epoch: 4 [57600/60000 (96%)]\t Loss: 0.255047 \t Accuracy:0.201%\n",
      "Train Epoch: 5 [0/60000 (0%)]\t Loss: 0.170420 \t Accuracy:0.205%\n",
      "Train Epoch: 5 [6400/60000 (11%)]\t Loss: 0.154012 \t Accuracy:0.201%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\t Loss: 0.338030 \t Accuracy:0.201%\n",
      "Train Epoch: 5 [19200/60000 (32%)]\t Loss: 0.121801 \t Accuracy:0.201%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\t Loss: 0.234212 \t Accuracy:0.201%\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t Loss: 0.287644 \t Accuracy:0.201%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\t Loss: 0.135413 \t Accuracy:0.201%\n",
      "Train Epoch: 5 [44800/60000 (75%)]\t Loss: 0.300929 \t Accuracy:0.201%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\t Loss: 0.196140 \t Accuracy:0.201%\n",
      "Train Epoch: 5 [57600/60000 (96%)]\t Loss: 0.249864 \t Accuracy:0.201%\n",
      "Train Epoch: 6 [0/60000 (0%)]\t Loss: 0.193601 \t Accuracy:0.207%\n",
      "Train Epoch: 6 [6400/60000 (11%)]\t Loss: 0.186174 \t Accuracy:0.202%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\t Loss: 0.114877 \t Accuracy:0.202%\n",
      "Train Epoch: 6 [19200/60000 (32%)]\t Loss: 0.141298 \t Accuracy:0.202%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\t Loss: 0.234424 \t Accuracy:0.202%\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t Loss: 0.197617 \t Accuracy:0.202%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\t Loss: 0.303234 \t Accuracy:0.202%\n",
      "Train Epoch: 6 [44800/60000 (75%)]\t Loss: 0.185969 \t Accuracy:0.202%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\t Loss: 0.128690 \t Accuracy:0.202%\n",
      "Train Epoch: 6 [57600/60000 (96%)]\t Loss: 0.205177 \t Accuracy:0.201%\n",
      "Train Epoch: 7 [0/60000 (0%)]\t Loss: 0.191587 \t Accuracy:0.205%\n",
      "Train Epoch: 7 [6400/60000 (11%)]\t Loss: 0.105164 \t Accuracy:0.202%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\t Loss: 0.232978 \t Accuracy:0.202%\n",
      "Train Epoch: 7 [19200/60000 (32%)]\t Loss: 0.140122 \t Accuracy:0.201%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\t Loss: 0.172988 \t Accuracy:0.201%\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t Loss: 0.118759 \t Accuracy:0.202%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\t Loss: 0.263313 \t Accuracy:0.201%\n",
      "Train Epoch: 7 [44800/60000 (75%)]\t Loss: 0.218284 \t Accuracy:0.201%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\t Loss: 0.178946 \t Accuracy:0.201%\n",
      "Train Epoch: 7 [57600/60000 (96%)]\t Loss: 0.189851 \t Accuracy:0.201%\n",
      "Train Epoch: 8 [0/60000 (0%)]\t Loss: 0.147940 \t Accuracy:0.205%\n",
      "Train Epoch: 8 [6400/60000 (11%)]\t Loss: 0.172357 \t Accuracy:0.202%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\t Loss: 0.168414 \t Accuracy:0.201%\n",
      "Train Epoch: 8 [19200/60000 (32%)]\t Loss: 0.192479 \t Accuracy:0.201%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\t Loss: 0.176545 \t Accuracy:0.201%\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t Loss: 0.130028 \t Accuracy:0.202%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\t Loss: 0.133892 \t Accuracy:0.202%\n",
      "Train Epoch: 8 [44800/60000 (75%)]\t Loss: 0.219862 \t Accuracy:0.202%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\t Loss: 0.358637 \t Accuracy:0.202%\n",
      "Train Epoch: 8 [57600/60000 (96%)]\t Loss: 0.272902 \t Accuracy:0.202%\n",
      "Train Epoch: 9 [0/60000 (0%)]\t Loss: 0.166254 \t Accuracy:0.203%\n",
      "Train Epoch: 9 [6400/60000 (11%)]\t Loss: 0.248707 \t Accuracy:0.202%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\t Loss: 0.245253 \t Accuracy:0.202%\n",
      "Train Epoch: 9 [19200/60000 (32%)]\t Loss: 0.100084 \t Accuracy:0.202%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\t Loss: 0.138267 \t Accuracy:0.202%\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t Loss: 0.239483 \t Accuracy:0.202%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\t Loss: 0.251971 \t Accuracy:0.202%\n",
      "Train Epoch: 9 [44800/60000 (75%)]\t Loss: 0.290739 \t Accuracy:0.202%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\t Loss: 0.261699 \t Accuracy:0.202%\n",
      "Train Epoch: 9 [57600/60000 (96%)]\t Loss: 0.133157 \t Accuracy:0.202%\n",
      "Train Epoch: 10 [0/60000 (0%)]\t Loss: 0.241241 \t Accuracy:0.200%\n",
      "Train Epoch: 10 [6400/60000 (11%)]\t Loss: 0.087105 \t Accuracy:0.202%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\t Loss: 0.337483 \t Accuracy:0.202%\n",
      "Train Epoch: 10 [19200/60000 (32%)]\t Loss: 0.158793 \t Accuracy:0.202%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\t Loss: 0.227456 \t Accuracy:0.202%\n",
      "Train Epoch: 10 [32000/60000 (53%)]\t Loss: 0.122316 \t Accuracy:0.202%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\t Loss: 0.141465 \t Accuracy:0.202%\n",
      "Train Epoch: 10 [44800/60000 (75%)]\t Loss: 0.231225 \t Accuracy:0.202%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\t Loss: 0.159211 \t Accuracy:0.202%\n",
      "Train Epoch: 10 [57600/60000 (96%)]\t Loss: 0.240896 \t Accuracy:0.202%\n",
      "Train Epoch: 11 [0/60000 (0%)]\t Loss: 0.199379 \t Accuracy:0.200%\n",
      "Train Epoch: 11 [6400/60000 (11%)]\t Loss: 0.113323 \t Accuracy:0.202%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\t Loss: 0.387109 \t Accuracy:0.202%\n",
      "Train Epoch: 11 [19200/60000 (32%)]\t Loss: 0.169337 \t Accuracy:0.202%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\t Loss: 0.357328 \t Accuracy:0.202%\n",
      "Train Epoch: 11 [32000/60000 (53%)]\t Loss: 0.120690 \t Accuracy:0.202%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\t Loss: 0.238593 \t Accuracy:0.202%\n",
      "Train Epoch: 11 [44800/60000 (75%)]\t Loss: 0.391027 \t Accuracy:0.202%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\t Loss: 0.231312 \t Accuracy:0.202%\n",
      "Train Epoch: 11 [57600/60000 (96%)]\t Loss: 0.244716 \t Accuracy:0.202%\n",
      "Train Epoch: 12 [0/60000 (0%)]\t Loss: 0.172195 \t Accuracy:0.202%\n",
      "Train Epoch: 12 [6400/60000 (11%)]\t Loss: 0.199956 \t Accuracy:0.203%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\t Loss: 0.140767 \t Accuracy:0.202%\n",
      "Train Epoch: 12 [19200/60000 (32%)]\t Loss: 0.199306 \t Accuracy:0.202%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\t Loss: 0.354020 \t Accuracy:0.202%\n",
      "Train Epoch: 12 [32000/60000 (53%)]\t Loss: 0.181318 \t Accuracy:0.202%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\t Loss: 0.241793 \t Accuracy:0.202%\n",
      "Train Epoch: 12 [44800/60000 (75%)]\t Loss: 0.215331 \t Accuracy:0.202%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\t Loss: 0.140414 \t Accuracy:0.202%\n",
      "Train Epoch: 12 [57600/60000 (96%)]\t Loss: 0.120885 \t Accuracy:0.202%\n",
      "Train Epoch: 13 [0/60000 (0%)]\t Loss: 0.107779 \t Accuracy:0.207%\n",
      "Train Epoch: 13 [6400/60000 (11%)]\t Loss: 0.136008 \t Accuracy:0.202%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\t Loss: 0.192783 \t Accuracy:0.202%\n",
      "Train Epoch: 13 [19200/60000 (32%)]\t Loss: 0.084412 \t Accuracy:0.202%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\t Loss: 0.199506 \t Accuracy:0.202%\n",
      "Train Epoch: 13 [32000/60000 (53%)]\t Loss: 0.063178 \t Accuracy:0.202%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\t Loss: 0.234728 \t Accuracy:0.202%\n",
      "Train Epoch: 13 [44800/60000 (75%)]\t Loss: 0.153333 \t Accuracy:0.202%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\t Loss: 0.334318 \t Accuracy:0.202%\n",
      "Train Epoch: 13 [57600/60000 (96%)]\t Loss: 0.143530 \t Accuracy:0.202%\n",
      "Train Epoch: 14 [0/60000 (0%)]\t Loss: 0.190614 \t Accuracy:0.198%\n",
      "Train Epoch: 14 [6400/60000 (11%)]\t Loss: 0.178873 \t Accuracy:0.203%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\t Loss: 0.183734 \t Accuracy:0.202%\n",
      "Train Epoch: 14 [19200/60000 (32%)]\t Loss: 0.185054 \t Accuracy:0.202%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\t Loss: 0.184424 \t Accuracy:0.202%\n",
      "Train Epoch: 14 [32000/60000 (53%)]\t Loss: 0.143341 \t Accuracy:0.202%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\t Loss: 0.225891 \t Accuracy:0.202%\n",
      "Train Epoch: 14 [44800/60000 (75%)]\t Loss: 0.251353 \t Accuracy:0.202%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\t Loss: 0.184647 \t Accuracy:0.202%\n",
      "Train Epoch: 14 [57600/60000 (96%)]\t Loss: 0.168355 \t Accuracy:0.202%\n",
      "Train Epoch: 15 [0/60000 (0%)]\t Loss: 0.171218 \t Accuracy:0.205%\n",
      "Train Epoch: 15 [6400/60000 (11%)]\t Loss: 0.150950 \t Accuracy:0.202%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\t Loss: 0.217925 \t Accuracy:0.202%\n",
      "Train Epoch: 15 [19200/60000 (32%)]\t Loss: 0.139472 \t Accuracy:0.202%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\t Loss: 0.155718 \t Accuracy:0.202%\n",
      "Train Epoch: 15 [32000/60000 (53%)]\t Loss: 0.175908 \t Accuracy:0.202%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\t Loss: 0.129011 \t Accuracy:0.202%\n",
      "Train Epoch: 15 [44800/60000 (75%)]\t Loss: 0.194537 \t Accuracy:0.202%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\t Loss: 0.276599 \t Accuracy:0.202%\n",
      "Train Epoch: 15 [57600/60000 (96%)]\t Loss: 0.089543 \t Accuracy:0.202%\n",
      "Train Epoch: 16 [0/60000 (0%)]\t Loss: 0.231822 \t Accuracy:0.200%\n",
      "Train Epoch: 16 [6400/60000 (11%)]\t Loss: 0.086112 \t Accuracy:0.203%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\t Loss: 0.172080 \t Accuracy:0.202%\n",
      "Train Epoch: 16 [19200/60000 (32%)]\t Loss: 0.252298 \t Accuracy:0.202%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\t Loss: 0.203592 \t Accuracy:0.202%\n",
      "Train Epoch: 16 [32000/60000 (53%)]\t Loss: 0.079668 \t Accuracy:0.202%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\t Loss: 0.186848 \t Accuracy:0.202%\n",
      "Train Epoch: 16 [44800/60000 (75%)]\t Loss: 0.137173 \t Accuracy:0.202%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\t Loss: 0.327309 \t Accuracy:0.202%\n",
      "Train Epoch: 16 [57600/60000 (96%)]\t Loss: 0.117928 \t Accuracy:0.202%\n",
      "Train Epoch: 17 [0/60000 (0%)]\t Loss: 0.143880 \t Accuracy:0.203%\n",
      "Train Epoch: 17 [6400/60000 (11%)]\t Loss: 0.230072 \t Accuracy:0.201%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\t Loss: 0.175730 \t Accuracy:0.201%\n",
      "Train Epoch: 17 [19200/60000 (32%)]\t Loss: 0.115079 \t Accuracy:0.202%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\t Loss: 0.188059 \t Accuracy:0.202%\n",
      "Train Epoch: 17 [32000/60000 (53%)]\t Loss: 0.093992 \t Accuracy:0.202%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\t Loss: 0.062680 \t Accuracy:0.202%\n",
      "Train Epoch: 17 [44800/60000 (75%)]\t Loss: 0.122671 \t Accuracy:0.202%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\t Loss: 0.250007 \t Accuracy:0.202%\n",
      "Train Epoch: 17 [57600/60000 (96%)]\t Loss: 0.295856 \t Accuracy:0.202%\n",
      "Train Epoch: 18 [0/60000 (0%)]\t Loss: 0.140877 \t Accuracy:0.207%\n",
      "Train Epoch: 18 [6400/60000 (11%)]\t Loss: 0.137802 \t Accuracy:0.202%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\t Loss: 0.275822 \t Accuracy:0.202%\n",
      "Train Epoch: 18 [19200/60000 (32%)]\t Loss: 0.141992 \t Accuracy:0.202%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\t Loss: 0.283443 \t Accuracy:0.202%\n",
      "Train Epoch: 18 [32000/60000 (53%)]\t Loss: 0.345607 \t Accuracy:0.202%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\t Loss: 0.183148 \t Accuracy:0.202%\n",
      "Train Epoch: 18 [44800/60000 (75%)]\t Loss: 0.136006 \t Accuracy:0.202%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\t Loss: 0.157886 \t Accuracy:0.202%\n",
      "Train Epoch: 18 [57600/60000 (96%)]\t Loss: 0.093906 \t Accuracy:0.202%\n",
      "Train Epoch: 19 [0/60000 (0%)]\t Loss: 0.108544 \t Accuracy:0.207%\n",
      "Train Epoch: 19 [6400/60000 (11%)]\t Loss: 0.152454 \t Accuracy:0.203%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\t Loss: 0.168799 \t Accuracy:0.203%\n",
      "Train Epoch: 19 [19200/60000 (32%)]\t Loss: 0.316790 \t Accuracy:0.202%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\t Loss: 0.305551 \t Accuracy:0.202%\n",
      "Train Epoch: 19 [32000/60000 (53%)]\t Loss: 0.104598 \t Accuracy:0.202%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\t Loss: 0.168372 \t Accuracy:0.202%\n",
      "Train Epoch: 19 [44800/60000 (75%)]\t Loss: 0.196177 \t Accuracy:0.202%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\t Loss: 0.136399 \t Accuracy:0.202%\n",
      "Train Epoch: 19 [57600/60000 (96%)]\t Loss: 0.220235 \t Accuracy:0.202%\n",
      "Train Epoch: 20 [0/60000 (0%)]\t Loss: 0.165709 \t Accuracy:0.203%\n",
      "Train Epoch: 20 [6400/60000 (11%)]\t Loss: 0.100479 \t Accuracy:0.204%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\t Loss: 0.147870 \t Accuracy:0.203%\n",
      "Train Epoch: 20 [19200/60000 (32%)]\t Loss: 0.254041 \t Accuracy:0.203%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\t Loss: 0.176679 \t Accuracy:0.203%\n",
      "Train Epoch: 20 [32000/60000 (53%)]\t Loss: 0.155321 \t Accuracy:0.202%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\t Loss: 0.200340 \t Accuracy:0.202%\n",
      "Train Epoch: 20 [44800/60000 (75%)]\t Loss: 0.115219 \t Accuracy:0.202%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\t Loss: 0.200252 \t Accuracy:0.202%\n",
      "Train Epoch: 20 [57600/60000 (96%)]\t Loss: 0.187994 \t Accuracy:0.202%\n",
      "Train Epoch: 21 [0/60000 (0%)]\t Loss: 0.098107 \t Accuracy:0.208%\n",
      "Train Epoch: 21 [6400/60000 (11%)]\t Loss: 0.269848 \t Accuracy:0.202%\n",
      "Train Epoch: 21 [12800/60000 (21%)]\t Loss: 0.268066 \t Accuracy:0.202%\n",
      "Train Epoch: 21 [19200/60000 (32%)]\t Loss: 0.170864 \t Accuracy:0.202%\n",
      "Train Epoch: 21 [25600/60000 (43%)]\t Loss: 0.090167 \t Accuracy:0.202%\n",
      "Train Epoch: 21 [32000/60000 (53%)]\t Loss: 0.043731 \t Accuracy:0.202%\n",
      "Train Epoch: 21 [38400/60000 (64%)]\t Loss: 0.098654 \t Accuracy:0.202%\n",
      "Train Epoch: 21 [44800/60000 (75%)]\t Loss: 0.179716 \t Accuracy:0.202%\n",
      "Train Epoch: 21 [51200/60000 (85%)]\t Loss: 0.182689 \t Accuracy:0.202%\n",
      "Train Epoch: 21 [57600/60000 (96%)]\t Loss: 0.241881 \t Accuracy:0.202%\n",
      "Train Epoch: 22 [0/60000 (0%)]\t Loss: 0.183939 \t Accuracy:0.198%\n",
      "Train Epoch: 22 [6400/60000 (11%)]\t Loss: 0.086539 \t Accuracy:0.202%\n",
      "Train Epoch: 22 [12800/60000 (21%)]\t Loss: 0.151956 \t Accuracy:0.203%\n",
      "Train Epoch: 22 [19200/60000 (32%)]\t Loss: 0.219247 \t Accuracy:0.202%\n",
      "Train Epoch: 22 [25600/60000 (43%)]\t Loss: 0.321608 \t Accuracy:0.202%\n",
      "Train Epoch: 22 [32000/60000 (53%)]\t Loss: 0.255161 \t Accuracy:0.202%\n",
      "Train Epoch: 22 [38400/60000 (64%)]\t Loss: 0.146436 \t Accuracy:0.202%\n",
      "Train Epoch: 22 [44800/60000 (75%)]\t Loss: 0.200023 \t Accuracy:0.202%\n",
      "Train Epoch: 22 [51200/60000 (85%)]\t Loss: 0.127991 \t Accuracy:0.202%\n",
      "Train Epoch: 22 [57600/60000 (96%)]\t Loss: 0.143356 \t Accuracy:0.202%\n",
      "Train Epoch: 23 [0/60000 (0%)]\t Loss: 0.172749 \t Accuracy:0.202%\n",
      "Train Epoch: 23 [6400/60000 (11%)]\t Loss: 0.177744 \t Accuracy:0.203%\n",
      "Train Epoch: 23 [12800/60000 (21%)]\t Loss: 0.131093 \t Accuracy:0.203%\n",
      "Train Epoch: 23 [19200/60000 (32%)]\t Loss: 0.147749 \t Accuracy:0.202%\n",
      "Train Epoch: 23 [25600/60000 (43%)]\t Loss: 0.227894 \t Accuracy:0.202%\n",
      "Train Epoch: 23 [32000/60000 (53%)]\t Loss: 0.119008 \t Accuracy:0.202%\n",
      "Train Epoch: 23 [38400/60000 (64%)]\t Loss: 0.111500 \t Accuracy:0.202%\n",
      "Train Epoch: 23 [44800/60000 (75%)]\t Loss: 0.168976 \t Accuracy:0.202%\n",
      "Train Epoch: 23 [51200/60000 (85%)]\t Loss: 0.279728 \t Accuracy:0.202%\n",
      "Train Epoch: 23 [57600/60000 (96%)]\t Loss: 0.178648 \t Accuracy:0.202%\n",
      "Train Epoch: 24 [0/60000 (0%)]\t Loss: 0.113326 \t Accuracy:0.208%\n",
      "Train Epoch: 24 [6400/60000 (11%)]\t Loss: 0.232878 \t Accuracy:0.202%\n",
      "Train Epoch: 24 [12800/60000 (21%)]\t Loss: 0.218867 \t Accuracy:0.203%\n",
      "Train Epoch: 24 [19200/60000 (32%)]\t Loss: 0.123305 \t Accuracy:0.202%\n",
      "Train Epoch: 24 [25600/60000 (43%)]\t Loss: 0.170873 \t Accuracy:0.203%\n",
      "Train Epoch: 24 [32000/60000 (53%)]\t Loss: 0.162212 \t Accuracy:0.203%\n",
      "Train Epoch: 24 [38400/60000 (64%)]\t Loss: 0.171975 \t Accuracy:0.203%\n",
      "Train Epoch: 24 [44800/60000 (75%)]\t Loss: 0.079616 \t Accuracy:0.203%\n",
      "Train Epoch: 24 [51200/60000 (85%)]\t Loss: 0.095950 \t Accuracy:0.203%\n",
      "Train Epoch: 24 [57600/60000 (96%)]\t Loss: 0.184739 \t Accuracy:0.202%\n",
      "Train Epoch: 25 [0/60000 (0%)]\t Loss: 0.210533 \t Accuracy:0.200%\n",
      "Train Epoch: 25 [6400/60000 (11%)]\t Loss: 0.153925 \t Accuracy:0.203%\n",
      "Train Epoch: 25 [12800/60000 (21%)]\t Loss: 0.205448 \t Accuracy:0.203%\n",
      "Train Epoch: 25 [19200/60000 (32%)]\t Loss: 0.169848 \t Accuracy:0.203%\n",
      "Train Epoch: 25 [25600/60000 (43%)]\t Loss: 0.250347 \t Accuracy:0.203%\n",
      "Train Epoch: 25 [32000/60000 (53%)]\t Loss: 0.073248 \t Accuracy:0.203%\n",
      "Train Epoch: 25 [38400/60000 (64%)]\t Loss: 0.178886 \t Accuracy:0.203%\n",
      "Train Epoch: 25 [44800/60000 (75%)]\t Loss: 0.232697 \t Accuracy:0.202%\n",
      "Train Epoch: 25 [51200/60000 (85%)]\t Loss: 0.146940 \t Accuracy:0.202%\n",
      "Train Epoch: 25 [57600/60000 (96%)]\t Loss: 0.227933 \t Accuracy:0.202%\n",
      "Train Epoch: 26 [0/60000 (0%)]\t Loss: 0.045953 \t Accuracy:0.210%\n",
      "Train Epoch: 26 [6400/60000 (11%)]\t Loss: 0.100227 \t Accuracy:0.203%\n",
      "Train Epoch: 26 [12800/60000 (21%)]\t Loss: 0.187065 \t Accuracy:0.203%\n",
      "Train Epoch: 26 [19200/60000 (32%)]\t Loss: 0.076558 \t Accuracy:0.203%\n",
      "Train Epoch: 26 [25600/60000 (43%)]\t Loss: 0.320009 \t Accuracy:0.203%\n",
      "Train Epoch: 26 [32000/60000 (53%)]\t Loss: 0.182342 \t Accuracy:0.203%\n",
      "Train Epoch: 26 [38400/60000 (64%)]\t Loss: 0.152565 \t Accuracy:0.203%\n",
      "Train Epoch: 26 [44800/60000 (75%)]\t Loss: 0.137659 \t Accuracy:0.203%\n",
      "Train Epoch: 26 [51200/60000 (85%)]\t Loss: 0.088984 \t Accuracy:0.203%\n",
      "Train Epoch: 26 [57600/60000 (96%)]\t Loss: 0.161947 \t Accuracy:0.202%\n",
      "Train Epoch: 27 [0/60000 (0%)]\t Loss: 0.144531 \t Accuracy:0.205%\n",
      "Train Epoch: 27 [6400/60000 (11%)]\t Loss: 0.140579 \t Accuracy:0.203%\n",
      "Train Epoch: 27 [12800/60000 (21%)]\t Loss: 0.214854 \t Accuracy:0.202%\n",
      "Train Epoch: 27 [19200/60000 (32%)]\t Loss: 0.164230 \t Accuracy:0.202%\n",
      "Train Epoch: 27 [25600/60000 (43%)]\t Loss: 0.239916 \t Accuracy:0.202%\n",
      "Train Epoch: 27 [32000/60000 (53%)]\t Loss: 0.273156 \t Accuracy:0.203%\n",
      "Train Epoch: 27 [38400/60000 (64%)]\t Loss: 0.195033 \t Accuracy:0.202%\n",
      "Train Epoch: 27 [44800/60000 (75%)]\t Loss: 0.176680 \t Accuracy:0.203%\n",
      "Train Epoch: 27 [51200/60000 (85%)]\t Loss: 0.215017 \t Accuracy:0.202%\n",
      "Train Epoch: 27 [57600/60000 (96%)]\t Loss: 0.185833 \t Accuracy:0.202%\n",
      "Train Epoch: 28 [0/60000 (0%)]\t Loss: 0.159472 \t Accuracy:0.205%\n",
      "Train Epoch: 28 [6400/60000 (11%)]\t Loss: 0.174395 \t Accuracy:0.202%\n",
      "Train Epoch: 28 [12800/60000 (21%)]\t Loss: 0.115595 \t Accuracy:0.202%\n",
      "Train Epoch: 28 [19200/60000 (32%)]\t Loss: 0.158986 \t Accuracy:0.202%\n",
      "Train Epoch: 28 [25600/60000 (43%)]\t Loss: 0.267756 \t Accuracy:0.202%\n",
      "Train Epoch: 28 [32000/60000 (53%)]\t Loss: 0.127240 \t Accuracy:0.202%\n",
      "Train Epoch: 28 [38400/60000 (64%)]\t Loss: 0.186846 \t Accuracy:0.202%\n",
      "Train Epoch: 28 [44800/60000 (75%)]\t Loss: 0.166413 \t Accuracy:0.202%\n",
      "Train Epoch: 28 [51200/60000 (85%)]\t Loss: 0.109614 \t Accuracy:0.202%\n",
      "Train Epoch: 28 [57600/60000 (96%)]\t Loss: 0.143706 \t Accuracy:0.202%\n",
      "Train Epoch: 29 [0/60000 (0%)]\t Loss: 0.117929 \t Accuracy:0.208%\n",
      "Train Epoch: 29 [6400/60000 (11%)]\t Loss: 0.142236 \t Accuracy:0.203%\n",
      "Train Epoch: 29 [12800/60000 (21%)]\t Loss: 0.159387 \t Accuracy:0.203%\n",
      "Train Epoch: 29 [19200/60000 (32%)]\t Loss: 0.172597 \t Accuracy:0.203%\n",
      "Train Epoch: 29 [25600/60000 (43%)]\t Loss: 0.150132 \t Accuracy:0.203%\n",
      "Train Epoch: 29 [32000/60000 (53%)]\t Loss: 0.056892 \t Accuracy:0.203%\n",
      "Train Epoch: 29 [38400/60000 (64%)]\t Loss: 0.082304 \t Accuracy:0.203%\n",
      "Train Epoch: 29 [44800/60000 (75%)]\t Loss: 0.169608 \t Accuracy:0.203%\n",
      "Train Epoch: 29 [51200/60000 (85%)]\t Loss: 0.194574 \t Accuracy:0.203%\n",
      "Train Epoch: 29 [57600/60000 (96%)]\t Loss: 0.190878 \t Accuracy:0.203%\n",
      "Test accuracy:0.935%\n",
      "Total Execution Time: 136.00 minutes\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
