{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a179439-171a-4003-b7c0-f041cc70567a",
   "metadata": {},
   "source": [
    "# Research project - Distributed deep learning with Pythorch\n",
    "\n",
    "## Local version\n",
    "\n",
    "### AI Specialization University Minuto de Dios\n",
    "\n",
    "#### Made by: Michael Andr√©s Mora Poveda\n",
    "\n",
    "Objective:\n",
    "\n",
    "The aim of this notebook is apply convolutional neural networks to train a multiclassifier with MNIST dataset \n",
    "in local version and with Pytorch deep learning framework. Moreover, it's important taking into account that other\n",
    "purpose is calculate the time processing to contrast it with on-cloud distributed version on Azure.\n",
    "\n",
    "All the descriptions and explanations about this dataset could be find in the following url:\n",
    "\n",
    "**https://www.tensorflow.org/datasets/catalog/mnist**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7408adc3-fac1-422c-954b-15ee54c1d6c7",
   "metadata": {},
   "source": [
    "##### 1. Import the respective packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d6553b-5dd4-4150-9503-62d16ef8f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pendulum\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3df373-9571-4b01-9335-1045cd5e39ee",
   "metadata": {},
   "source": [
    "##### 2. Parameterize the transformations to normalize the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aabeb5e-a587-410a-ac8c-ccbb52853473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones y carga del conjunto de entrenamiento\n",
    "def transform_data():\n",
    "    \"\"\"\n",
    "    Apply the Compose function to convert an image to tensor\n",
    "    and normalize the MNIST pictures with mean and standard \n",
    "    deviation equal to 0.5\n",
    "\n",
    "    Args: \n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        Pictures normalized.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e8ddc-9209-4f6c-9a52-6f4b8c464f0d",
   "metadata": {},
   "source": [
    "##### 3. Import the dataset directly from Pytorch dataset module and apply the data loader function to save all the files into data folder and visualize any properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8fc7380-f6b8-4e22-8e8e-a36eb0c04390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_df(batch_size: int):\n",
    "    \"\"\"\n",
    "    Import, save and load the MNIST dataset from Pythorch.datasets module.\n",
    "\n",
    "    Args: \n",
    "        batch_size (int): Number of pictures to each batch.\n",
    "\n",
    "    Returns:\n",
    "        train_loader: Training set \n",
    "        test_loader: Testing set \n",
    "    \"\"\"\n",
    "    train_set = datasets.MNIST(root='./data_source', train = True, transform=transform_data(), download=True)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_set = datasets.MNIST(root='./data_source', train=False, transform=transform_data(), download=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd3159-2d16-4b8d-a064-c24076a7d2cc",
   "metadata": {},
   "source": [
    "##### 4. Define the Net class to instiate the convolutional neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d705f14d-e633-4b98-94ee-ffc5c0602447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d27083-3e6c-47e8-9840-2113e39d2123",
   "metadata": {},
   "source": [
    "##### 5. Define the training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840081e2-aeb1-4d87-9d9e-9196e88c49bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(cnn_model, train_loader, criterion, optimizer, epochs):\n",
    "    \"\"\"\n",
    "    This function train our CNN.\n",
    "\n",
    "    Args:\n",
    "        cnn_model (Net): Our CNN model instantiate with Pytorch\n",
    "        train_loader (DataLoader object): Training set normalized\n",
    "        criterion (torch.nn object): Loss function\n",
    "        optimizer(torch.optim object): Optimizer to backpropagation process\n",
    "        epoch (int): Number of epochs to train our model\n",
    "\n",
    "    Return:\n",
    "        Print the results of each training epoch.    \n",
    "    \"\"\"\n",
    "    cnn_model.train()\n",
    "    batch_size = 128\n",
    "    error = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            var_x_batch = x_batch.float()\n",
    "            var_y_batch = y_batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = cnn_model(var_x_batch)\n",
    "            loss = error(outputs, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #Total correct predictions:\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            correct += (predicted == var_y_batch).sum() \n",
    "            \n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f} \\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, \n",
    "                    batch_idx * len(x_batch), \n",
    "                    len(train_loader.dataset),\n",
    "                    100 * batch_idx / len(train_loader), \n",
    "                    loss.item(),\n",
    "                    float(correct*100) / float(len(train_loader.dataset) * (batch_idx +1))\n",
    "                )\n",
    "                         \n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ec196-ba6c-4314-80c8-2257b5964021",
   "metadata": {},
   "source": [
    "##### 6. Define the testing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b26a67-6632-433c-ba29-a12b2d5558c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnn(cnn_model, test_loader):\n",
    "    \"\"\"\n",
    "    This function test our CNN.\n",
    "\n",
    "    Args:\n",
    "        cnn_model (Net): Our CNN model instantiate with Pytorch\n",
    "        test_loader (DataLoader object): Testing set normalized\n",
    "        criterion (torch.nn object): Loss function\n",
    "        epoch (int): Number of epochs to train our model\n",
    "\n",
    "    Return:\n",
    "        Print the performance metrics to each one of our training epochs.       \n",
    "    \"\"\"\n",
    "    batch_size =  128\n",
    "    correct = 0\n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        test_imgs = Variable(test_imgs).float()\n",
    "        output = cnn_model(test_imgs)\n",
    "        predicted = torch.max(output, 1)[1]\n",
    "        correct += (predicted == test_labels).sum()\n",
    "    print(\"Test accuracy:{:.3f}%\".format(float(correct) / (len(test_loader)*batch_size))) \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2025657b-f88c-4bc8-a615-f3b072fbd465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Apply each function defined previously to our CNN model:\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate the datasets and dataloaders:\n",
    "    train_loader, test_loader = load_mnist_df(batch_size = 128)\n",
    "\n",
    "    # Visualize any properties:\n",
    "    data_iter = iter(train_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    num_batches = len(train_loader)\n",
    "    print(\"Total batches to training:\", num_batches)\n",
    "    \n",
    "    # Pictures and label shapes:\n",
    "    print(\"Pictures shape:\", images.shape)\n",
    "    print(\"Labels column shape:\", labels.shape)\n",
    "\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    num_batches = len(test_loader)\n",
    "    print(\"Total batches to testing:\", num_batches)\n",
    "    \n",
    "    # Pictures and label shapes:\n",
    "    print(\"Pictures shape:\", images.shape)\n",
    "    print(\"Labels column shape:\", labels.shape)\n",
    "\n",
    "\n",
    "    # Instantiate the CNN, loss function and optimizer:\n",
    "    cnn_model = Net()\n",
    "    print(cnn_model)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Start time execution:\n",
    "    start_time = pendulum.now()\n",
    "\n",
    "    # Training and testing:\n",
    "    train_cnn(cnn_model, train_loader, criterion, optimizer, epochs = 30)\n",
    "    test_cnn(cnn_model, test_loader)\n",
    "\n",
    "\n",
    "    # Final time execution:\n",
    "    end_time = pendulum.now()\n",
    "    execution_time = (end_time - start_time).in_minutes()\n",
    "    print(f\"Total Execution Time: {execution_time:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d6715c-b60d-46df-8d26-04a08870816b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to training: 469\n",
      "Pictures shape: torch.Size([128, 1, 28, 28])\n",
      "Labels column shape: torch.Size([128])\n",
      "Total batches to testing: 79\n",
      "Pictures shape: torch.Size([128, 1, 28, 28])\n",
      "Labels column shape: torch.Size([128])\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 0 [0/60000 (0%)]\t Loss: 2.319230 \t Accuracy:0.022%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xh/l9ggclrd1fx2brvxlnc_9hv40000gn/T/ipykernel_2166/161431047.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [6400/60000 (11%)]\t Loss: 0.989123 \t Accuracy:0.111%\n",
      "Train Epoch: 0 [12800/60000 (21%)]\t Loss: 0.720497 \t Accuracy:0.136%\n",
      "Train Epoch: 0 [19200/60000 (32%)]\t Loss: 0.410224 \t Accuracy:0.149%\n",
      "Train Epoch: 0 [25600/60000 (43%)]\t Loss: 0.352141 \t Accuracy:0.157%\n",
      "Train Epoch: 0 [32000/60000 (53%)]\t Loss: 0.520004 \t Accuracy:0.162%\n",
      "Train Epoch: 0 [38400/60000 (64%)]\t Loss: 0.457121 \t Accuracy:0.165%\n",
      "Train Epoch: 0 [44800/60000 (75%)]\t Loss: 0.429300 \t Accuracy:0.168%\n",
      "Train Epoch: 0 [51200/60000 (85%)]\t Loss: 0.340333 \t Accuracy:0.171%\n",
      "Train Epoch: 0 [57600/60000 (96%)]\t Loss: 0.316557 \t Accuracy:0.173%\n",
      "Train Epoch: 1 [0/60000 (0%)]\t Loss: 0.335991 \t Accuracy:0.183%\n",
      "Train Epoch: 1 [6400/60000 (11%)]\t Loss: 0.535936 \t Accuracy:0.189%\n",
      "Train Epoch: 1 [12800/60000 (21%)]\t Loss: 0.237899 \t Accuracy:0.190%\n",
      "Train Epoch: 1 [19200/60000 (32%)]\t Loss: 0.309124 \t Accuracy:0.191%\n",
      "Train Epoch: 1 [25600/60000 (43%)]\t Loss: 0.331427 \t Accuracy:0.191%\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t Loss: 0.173197 \t Accuracy:0.191%\n",
      "Train Epoch: 1 [38400/60000 (64%)]\t Loss: 0.420767 \t Accuracy:0.191%\n",
      "Train Epoch: 1 [44800/60000 (75%)]\t Loss: 0.334169 \t Accuracy:0.192%\n",
      "Train Epoch: 1 [51200/60000 (85%)]\t Loss: 0.128177 \t Accuracy:0.192%\n",
      "Train Epoch: 1 [57600/60000 (96%)]\t Loss: 0.459028 \t Accuracy:0.192%\n",
      "Train Epoch: 2 [0/60000 (0%)]\t Loss: 0.370634 \t Accuracy:0.188%\n",
      "Train Epoch: 2 [6400/60000 (11%)]\t Loss: 0.332615 \t Accuracy:0.193%\n",
      "Train Epoch: 2 [12800/60000 (21%)]\t Loss: 0.252395 \t Accuracy:0.194%\n",
      "Train Epoch: 2 [19200/60000 (32%)]\t Loss: 0.242560 \t Accuracy:0.193%\n",
      "Train Epoch: 2 [25600/60000 (43%)]\t Loss: 0.257375 \t Accuracy:0.194%\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t Loss: 0.235422 \t Accuracy:0.194%\n",
      "Train Epoch: 2 [38400/60000 (64%)]\t Loss: 0.338819 \t Accuracy:0.194%\n",
      "Train Epoch: 2 [44800/60000 (75%)]\t Loss: 0.211091 \t Accuracy:0.194%\n",
      "Train Epoch: 2 [51200/60000 (85%)]\t Loss: 0.300551 \t Accuracy:0.194%\n",
      "Train Epoch: 2 [57600/60000 (96%)]\t Loss: 0.359050 \t Accuracy:0.194%\n",
      "Train Epoch: 3 [0/60000 (0%)]\t Loss: 0.276251 \t Accuracy:0.195%\n",
      "Train Epoch: 3 [6400/60000 (11%)]\t Loss: 0.270519 \t Accuracy:0.196%\n",
      "Train Epoch: 3 [12800/60000 (21%)]\t Loss: 0.229017 \t Accuracy:0.196%\n",
      "Train Epoch: 3 [19200/60000 (32%)]\t Loss: 0.299931 \t Accuracy:0.196%\n",
      "Train Epoch: 3 [25600/60000 (43%)]\t Loss: 0.252002 \t Accuracy:0.196%\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t Loss: 0.356012 \t Accuracy:0.196%\n",
      "Train Epoch: 3 [38400/60000 (64%)]\t Loss: 0.235448 \t Accuracy:0.196%\n",
      "Train Epoch: 3 [44800/60000 (75%)]\t Loss: 0.271513 \t Accuracy:0.196%\n",
      "Train Epoch: 3 [51200/60000 (85%)]\t Loss: 0.223487 \t Accuracy:0.196%\n",
      "Train Epoch: 3 [57600/60000 (96%)]\t Loss: 0.224028 \t Accuracy:0.196%\n",
      "Train Epoch: 4 [0/60000 (0%)]\t Loss: 0.250018 \t Accuracy:0.195%\n",
      "Train Epoch: 4 [6400/60000 (11%)]\t Loss: 0.172814 \t Accuracy:0.196%\n",
      "Train Epoch: 4 [12800/60000 (21%)]\t Loss: 0.251273 \t Accuracy:0.196%\n",
      "Train Epoch: 4 [19200/60000 (32%)]\t Loss: 0.456318 \t Accuracy:0.196%\n",
      "Train Epoch: 4 [25600/60000 (43%)]\t Loss: 0.277268 \t Accuracy:0.196%\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t Loss: 0.215742 \t Accuracy:0.196%\n",
      "Train Epoch: 4 [38400/60000 (64%)]\t Loss: 0.273782 \t Accuracy:0.196%\n",
      "Train Epoch: 4 [44800/60000 (75%)]\t Loss: 0.264974 \t Accuracy:0.196%\n",
      "Train Epoch: 4 [51200/60000 (85%)]\t Loss: 0.394219 \t Accuracy:0.196%\n",
      "Train Epoch: 4 [57600/60000 (96%)]\t Loss: 0.348805 \t Accuracy:0.196%\n",
      "Train Epoch: 5 [0/60000 (0%)]\t Loss: 0.397190 \t Accuracy:0.192%\n",
      "Train Epoch: 5 [6400/60000 (11%)]\t Loss: 0.185337 \t Accuracy:0.195%\n",
      "Train Epoch: 5 [12800/60000 (21%)]\t Loss: 0.417243 \t Accuracy:0.195%\n",
      "Train Epoch: 5 [19200/60000 (32%)]\t Loss: 0.165812 \t Accuracy:0.195%\n",
      "Train Epoch: 5 [25600/60000 (43%)]\t Loss: 0.174042 \t Accuracy:0.195%\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t Loss: 0.180505 \t Accuracy:0.195%\n",
      "Train Epoch: 5 [38400/60000 (64%)]\t Loss: 0.147431 \t Accuracy:0.196%\n",
      "Train Epoch: 5 [44800/60000 (75%)]\t Loss: 0.414476 \t Accuracy:0.196%\n",
      "Train Epoch: 5 [51200/60000 (85%)]\t Loss: 0.248993 \t Accuracy:0.196%\n",
      "Train Epoch: 5 [57600/60000 (96%)]\t Loss: 0.163239 \t Accuracy:0.196%\n",
      "Train Epoch: 6 [0/60000 (0%)]\t Loss: 0.186401 \t Accuracy:0.200%\n",
      "Train Epoch: 6 [6400/60000 (11%)]\t Loss: 0.284531 \t Accuracy:0.196%\n",
      "Train Epoch: 6 [12800/60000 (21%)]\t Loss: 0.268217 \t Accuracy:0.196%\n",
      "Train Epoch: 6 [19200/60000 (32%)]\t Loss: 0.183554 \t Accuracy:0.196%\n",
      "Train Epoch: 6 [25600/60000 (43%)]\t Loss: 0.242979 \t Accuracy:0.197%\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t Loss: 0.173872 \t Accuracy:0.197%\n",
      "Train Epoch: 6 [38400/60000 (64%)]\t Loss: 0.161467 \t Accuracy:0.197%\n",
      "Train Epoch: 6 [44800/60000 (75%)]\t Loss: 0.262982 \t Accuracy:0.197%\n",
      "Train Epoch: 6 [51200/60000 (85%)]\t Loss: 0.157875 \t Accuracy:0.197%\n",
      "Train Epoch: 6 [57600/60000 (96%)]\t Loss: 0.302242 \t Accuracy:0.197%\n",
      "Train Epoch: 7 [0/60000 (0%)]\t Loss: 0.168441 \t Accuracy:0.205%\n",
      "Train Epoch: 7 [6400/60000 (11%)]\t Loss: 0.297222 \t Accuracy:0.199%\n",
      "Train Epoch: 7 [12800/60000 (21%)]\t Loss: 0.243532 \t Accuracy:0.198%\n",
      "Train Epoch: 7 [19200/60000 (32%)]\t Loss: 0.165231 \t Accuracy:0.198%\n",
      "Train Epoch: 7 [25600/60000 (43%)]\t Loss: 0.168499 \t Accuracy:0.198%\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t Loss: 0.246743 \t Accuracy:0.198%\n",
      "Train Epoch: 7 [38400/60000 (64%)]\t Loss: 0.157554 \t Accuracy:0.198%\n",
      "Train Epoch: 7 [44800/60000 (75%)]\t Loss: 0.395367 \t Accuracy:0.198%\n",
      "Train Epoch: 7 [51200/60000 (85%)]\t Loss: 0.162249 \t Accuracy:0.198%\n",
      "Train Epoch: 7 [57600/60000 (96%)]\t Loss: 0.176550 \t Accuracy:0.198%\n",
      "Train Epoch: 8 [0/60000 (0%)]\t Loss: 0.365953 \t Accuracy:0.190%\n",
      "Train Epoch: 8 [6400/60000 (11%)]\t Loss: 0.095189 \t Accuracy:0.199%\n",
      "Train Epoch: 8 [12800/60000 (21%)]\t Loss: 0.406489 \t Accuracy:0.197%\n",
      "Train Epoch: 8 [19200/60000 (32%)]\t Loss: 0.088579 \t Accuracy:0.198%\n",
      "Train Epoch: 8 [25600/60000 (43%)]\t Loss: 0.223171 \t Accuracy:0.198%\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t Loss: 0.174201 \t Accuracy:0.197%\n",
      "Train Epoch: 8 [38400/60000 (64%)]\t Loss: 0.162114 \t Accuracy:0.197%\n",
      "Train Epoch: 8 [44800/60000 (75%)]\t Loss: 0.205260 \t Accuracy:0.197%\n",
      "Train Epoch: 8 [51200/60000 (85%)]\t Loss: 0.392001 \t Accuracy:0.197%\n",
      "Train Epoch: 8 [57600/60000 (96%)]\t Loss: 0.165720 \t Accuracy:0.197%\n",
      "Train Epoch: 9 [0/60000 (0%)]\t Loss: 0.438581 \t Accuracy:0.188%\n",
      "Train Epoch: 9 [6400/60000 (11%)]\t Loss: 0.156884 \t Accuracy:0.197%\n",
      "Train Epoch: 9 [12800/60000 (21%)]\t Loss: 0.247606 \t Accuracy:0.197%\n",
      "Train Epoch: 9 [19200/60000 (32%)]\t Loss: 0.352168 \t Accuracy:0.197%\n",
      "Train Epoch: 9 [25600/60000 (43%)]\t Loss: 0.434571 \t Accuracy:0.197%\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t Loss: 0.371276 \t Accuracy:0.197%\n",
      "Train Epoch: 9 [38400/60000 (64%)]\t Loss: 0.318875 \t Accuracy:0.197%\n",
      "Train Epoch: 9 [44800/60000 (75%)]\t Loss: 0.096002 \t Accuracy:0.197%\n",
      "Train Epoch: 9 [51200/60000 (85%)]\t Loss: 0.236124 \t Accuracy:0.197%\n",
      "Train Epoch: 9 [57600/60000 (96%)]\t Loss: 0.156084 \t Accuracy:0.197%\n",
      "Train Epoch: 10 [0/60000 (0%)]\t Loss: 0.307711 \t Accuracy:0.193%\n",
      "Train Epoch: 10 [6400/60000 (11%)]\t Loss: 0.226116 \t Accuracy:0.197%\n",
      "Train Epoch: 10 [12800/60000 (21%)]\t Loss: 0.323941 \t Accuracy:0.197%\n",
      "Train Epoch: 10 [19200/60000 (32%)]\t Loss: 0.235238 \t Accuracy:0.197%\n",
      "Train Epoch: 10 [25600/60000 (43%)]\t Loss: 0.354442 \t Accuracy:0.197%\n",
      "Train Epoch: 10 [32000/60000 (53%)]\t Loss: 0.191899 \t Accuracy:0.197%\n",
      "Train Epoch: 10 [38400/60000 (64%)]\t Loss: 0.280698 \t Accuracy:0.197%\n",
      "Train Epoch: 10 [44800/60000 (75%)]\t Loss: 0.328834 \t Accuracy:0.197%\n",
      "Train Epoch: 10 [51200/60000 (85%)]\t Loss: 0.206458 \t Accuracy:0.197%\n",
      "Train Epoch: 10 [57600/60000 (96%)]\t Loss: 0.325287 \t Accuracy:0.197%\n",
      "Train Epoch: 11 [0/60000 (0%)]\t Loss: 0.203524 \t Accuracy:0.198%\n",
      "Train Epoch: 11 [6400/60000 (11%)]\t Loss: 0.282384 \t Accuracy:0.199%\n",
      "Train Epoch: 11 [12800/60000 (21%)]\t Loss: 0.274685 \t Accuracy:0.197%\n",
      "Train Epoch: 11 [19200/60000 (32%)]\t Loss: 0.242996 \t Accuracy:0.197%\n",
      "Train Epoch: 11 [25600/60000 (43%)]\t Loss: 0.383761 \t Accuracy:0.197%\n",
      "Train Epoch: 11 [32000/60000 (53%)]\t Loss: 0.364972 \t Accuracy:0.197%\n",
      "Train Epoch: 11 [38400/60000 (64%)]\t Loss: 0.256369 \t Accuracy:0.197%\n",
      "Train Epoch: 11 [44800/60000 (75%)]\t Loss: 0.370570 \t Accuracy:0.197%\n",
      "Train Epoch: 11 [51200/60000 (85%)]\t Loss: 0.354418 \t Accuracy:0.197%\n",
      "Train Epoch: 11 [57600/60000 (96%)]\t Loss: 0.146701 \t Accuracy:0.197%\n",
      "Train Epoch: 12 [0/60000 (0%)]\t Loss: 0.175933 \t Accuracy:0.203%\n",
      "Train Epoch: 12 [6400/60000 (11%)]\t Loss: 0.184375 \t Accuracy:0.198%\n",
      "Train Epoch: 12 [12800/60000 (21%)]\t Loss: 0.134062 \t Accuracy:0.198%\n",
      "Train Epoch: 12 [19200/60000 (32%)]\t Loss: 0.254498 \t Accuracy:0.198%\n",
      "Train Epoch: 12 [25600/60000 (43%)]\t Loss: 0.343028 \t Accuracy:0.198%\n",
      "Train Epoch: 12 [32000/60000 (53%)]\t Loss: 0.466988 \t Accuracy:0.198%\n",
      "Train Epoch: 12 [38400/60000 (64%)]\t Loss: 0.189144 \t Accuracy:0.198%\n",
      "Train Epoch: 12 [44800/60000 (75%)]\t Loss: 0.227755 \t Accuracy:0.198%\n",
      "Train Epoch: 12 [51200/60000 (85%)]\t Loss: 0.291034 \t Accuracy:0.197%\n",
      "Train Epoch: 12 [57600/60000 (96%)]\t Loss: 0.338032 \t Accuracy:0.197%\n",
      "Train Epoch: 13 [0/60000 (0%)]\t Loss: 0.207416 \t Accuracy:0.202%\n",
      "Train Epoch: 13 [6400/60000 (11%)]\t Loss: 0.168236 \t Accuracy:0.200%\n",
      "Train Epoch: 13 [12800/60000 (21%)]\t Loss: 0.294832 \t Accuracy:0.199%\n",
      "Train Epoch: 13 [19200/60000 (32%)]\t Loss: 0.181419 \t Accuracy:0.198%\n",
      "Train Epoch: 13 [25600/60000 (43%)]\t Loss: 0.167928 \t Accuracy:0.198%\n",
      "Train Epoch: 13 [32000/60000 (53%)]\t Loss: 0.247854 \t Accuracy:0.198%\n",
      "Train Epoch: 13 [38400/60000 (64%)]\t Loss: 0.107137 \t Accuracy:0.198%\n",
      "Train Epoch: 13 [44800/60000 (75%)]\t Loss: 0.205534 \t Accuracy:0.198%\n",
      "Train Epoch: 13 [51200/60000 (85%)]\t Loss: 0.220216 \t Accuracy:0.198%\n",
      "Train Epoch: 13 [57600/60000 (96%)]\t Loss: 0.198604 \t Accuracy:0.198%\n",
      "Train Epoch: 14 [0/60000 (0%)]\t Loss: 0.402394 \t Accuracy:0.193%\n",
      "Train Epoch: 14 [6400/60000 (11%)]\t Loss: 0.362788 \t Accuracy:0.197%\n",
      "Train Epoch: 14 [12800/60000 (21%)]\t Loss: 0.443388 \t Accuracy:0.198%\n",
      "Train Epoch: 14 [19200/60000 (32%)]\t Loss: 0.209125 \t Accuracy:0.198%\n",
      "Train Epoch: 14 [25600/60000 (43%)]\t Loss: 0.135104 \t Accuracy:0.198%\n",
      "Train Epoch: 14 [32000/60000 (53%)]\t Loss: 0.415099 \t Accuracy:0.198%\n",
      "Train Epoch: 14 [38400/60000 (64%)]\t Loss: 0.300988 \t Accuracy:0.198%\n",
      "Train Epoch: 14 [44800/60000 (75%)]\t Loss: 0.228974 \t Accuracy:0.198%\n",
      "Train Epoch: 14 [51200/60000 (85%)]\t Loss: 0.265184 \t Accuracy:0.198%\n",
      "Train Epoch: 14 [57600/60000 (96%)]\t Loss: 0.322130 \t Accuracy:0.198%\n",
      "Train Epoch: 15 [0/60000 (0%)]\t Loss: 0.163016 \t Accuracy:0.200%\n",
      "Train Epoch: 15 [6400/60000 (11%)]\t Loss: 0.168983 \t Accuracy:0.198%\n",
      "Train Epoch: 15 [12800/60000 (21%)]\t Loss: 0.271117 \t Accuracy:0.198%\n",
      "Train Epoch: 15 [19200/60000 (32%)]\t Loss: 0.316854 \t Accuracy:0.198%\n",
      "Train Epoch: 15 [25600/60000 (43%)]\t Loss: 0.274254 \t Accuracy:0.198%\n",
      "Train Epoch: 15 [32000/60000 (53%)]\t Loss: 0.165457 \t Accuracy:0.198%\n",
      "Train Epoch: 15 [38400/60000 (64%)]\t Loss: 0.206397 \t Accuracy:0.198%\n",
      "Train Epoch: 15 [44800/60000 (75%)]\t Loss: 0.382498 \t Accuracy:0.197%\n",
      "Train Epoch: 15 [51200/60000 (85%)]\t Loss: 0.415128 \t Accuracy:0.197%\n",
      "Train Epoch: 15 [57600/60000 (96%)]\t Loss: 0.218500 \t Accuracy:0.197%\n",
      "Train Epoch: 16 [0/60000 (0%)]\t Loss: 0.250457 \t Accuracy:0.197%\n",
      "Train Epoch: 16 [6400/60000 (11%)]\t Loss: 0.269981 \t Accuracy:0.198%\n",
      "Train Epoch: 16 [12800/60000 (21%)]\t Loss: 0.205151 \t Accuracy:0.199%\n",
      "Train Epoch: 16 [19200/60000 (32%)]\t Loss: 0.293557 \t Accuracy:0.198%\n",
      "Train Epoch: 16 [25600/60000 (43%)]\t Loss: 0.243995 \t Accuracy:0.198%\n",
      "Train Epoch: 16 [32000/60000 (53%)]\t Loss: 0.198680 \t Accuracy:0.198%\n",
      "Train Epoch: 16 [38400/60000 (64%)]\t Loss: 0.252411 \t Accuracy:0.198%\n",
      "Train Epoch: 16 [44800/60000 (75%)]\t Loss: 0.357883 \t Accuracy:0.198%\n",
      "Train Epoch: 16 [51200/60000 (85%)]\t Loss: 0.155435 \t Accuracy:0.198%\n",
      "Train Epoch: 16 [57600/60000 (96%)]\t Loss: 0.210270 \t Accuracy:0.198%\n",
      "Train Epoch: 17 [0/60000 (0%)]\t Loss: 0.264215 \t Accuracy:0.198%\n",
      "Train Epoch: 17 [6400/60000 (11%)]\t Loss: 0.175113 \t Accuracy:0.199%\n",
      "Train Epoch: 17 [12800/60000 (21%)]\t Loss: 0.175481 \t Accuracy:0.199%\n",
      "Train Epoch: 17 [19200/60000 (32%)]\t Loss: 0.294525 \t Accuracy:0.198%\n",
      "Train Epoch: 17 [25600/60000 (43%)]\t Loss: 0.225171 \t Accuracy:0.198%\n",
      "Train Epoch: 17 [32000/60000 (53%)]\t Loss: 0.143726 \t Accuracy:0.198%\n",
      "Train Epoch: 17 [38400/60000 (64%)]\t Loss: 0.300446 \t Accuracy:0.198%\n",
      "Train Epoch: 17 [44800/60000 (75%)]\t Loss: 0.186045 \t Accuracy:0.198%\n",
      "Train Epoch: 17 [51200/60000 (85%)]\t Loss: 0.308282 \t Accuracy:0.198%\n",
      "Train Epoch: 17 [57600/60000 (96%)]\t Loss: 0.176070 \t Accuracy:0.198%\n",
      "Train Epoch: 18 [0/60000 (0%)]\t Loss: 0.149572 \t Accuracy:0.200%\n",
      "Train Epoch: 18 [6400/60000 (11%)]\t Loss: 0.212117 \t Accuracy:0.199%\n",
      "Train Epoch: 18 [12800/60000 (21%)]\t Loss: 0.158407 \t Accuracy:0.198%\n",
      "Train Epoch: 18 [19200/60000 (32%)]\t Loss: 0.210658 \t Accuracy:0.198%\n",
      "Train Epoch: 18 [25600/60000 (43%)]\t Loss: 0.154314 \t Accuracy:0.198%\n",
      "Train Epoch: 18 [32000/60000 (53%)]\t Loss: 0.304067 \t Accuracy:0.198%\n",
      "Train Epoch: 18 [38400/60000 (64%)]\t Loss: 0.141197 \t Accuracy:0.198%\n",
      "Train Epoch: 18 [44800/60000 (75%)]\t Loss: 0.370228 \t Accuracy:0.198%\n",
      "Train Epoch: 18 [51200/60000 (85%)]\t Loss: 0.214033 \t Accuracy:0.198%\n",
      "Train Epoch: 18 [57600/60000 (96%)]\t Loss: 0.135438 \t Accuracy:0.198%\n",
      "Train Epoch: 19 [0/60000 (0%)]\t Loss: 0.169805 \t Accuracy:0.198%\n",
      "Train Epoch: 19 [6400/60000 (11%)]\t Loss: 0.322150 \t Accuracy:0.198%\n",
      "Train Epoch: 19 [12800/60000 (21%)]\t Loss: 0.230371 \t Accuracy:0.198%\n",
      "Train Epoch: 19 [19200/60000 (32%)]\t Loss: 0.225953 \t Accuracy:0.198%\n",
      "Train Epoch: 19 [25600/60000 (43%)]\t Loss: 0.550621 \t Accuracy:0.198%\n",
      "Train Epoch: 19 [32000/60000 (53%)]\t Loss: 0.400526 \t Accuracy:0.198%\n",
      "Train Epoch: 19 [38400/60000 (64%)]\t Loss: 0.204064 \t Accuracy:0.198%\n",
      "Train Epoch: 19 [44800/60000 (75%)]\t Loss: 0.270337 \t Accuracy:0.198%\n",
      "Train Epoch: 19 [51200/60000 (85%)]\t Loss: 0.215240 \t Accuracy:0.198%\n",
      "Train Epoch: 19 [57600/60000 (96%)]\t Loss: 0.410467 \t Accuracy:0.198%\n",
      "Train Epoch: 20 [0/60000 (0%)]\t Loss: 0.203697 \t Accuracy:0.198%\n",
      "Train Epoch: 20 [6400/60000 (11%)]\t Loss: 0.205525 \t Accuracy:0.197%\n",
      "Train Epoch: 20 [12800/60000 (21%)]\t Loss: 0.138983 \t Accuracy:0.198%\n",
      "Train Epoch: 20 [19200/60000 (32%)]\t Loss: 0.303913 \t Accuracy:0.198%\n",
      "Train Epoch: 20 [25600/60000 (43%)]\t Loss: 0.217448 \t Accuracy:0.197%\n",
      "Train Epoch: 20 [32000/60000 (53%)]\t Loss: 0.175782 \t Accuracy:0.197%\n",
      "Train Epoch: 20 [38400/60000 (64%)]\t Loss: 0.153453 \t Accuracy:0.198%\n",
      "Train Epoch: 20 [44800/60000 (75%)]\t Loss: 0.412403 \t Accuracy:0.198%\n",
      "Train Epoch: 20 [51200/60000 (85%)]\t Loss: 0.210502 \t Accuracy:0.198%\n",
      "Train Epoch: 20 [57600/60000 (96%)]\t Loss: 0.437707 \t Accuracy:0.197%\n",
      "Train Epoch: 21 [0/60000 (0%)]\t Loss: 0.158628 \t Accuracy:0.203%\n",
      "Train Epoch: 21 [6400/60000 (11%)]\t Loss: 0.187149 \t Accuracy:0.200%\n",
      "Train Epoch: 21 [12800/60000 (21%)]\t Loss: 0.298508 \t Accuracy:0.199%\n",
      "Train Epoch: 21 [19200/60000 (32%)]\t Loss: 0.322943 \t Accuracy:0.198%\n",
      "Train Epoch: 21 [25600/60000 (43%)]\t Loss: 0.228309 \t Accuracy:0.199%\n",
      "Train Epoch: 21 [32000/60000 (53%)]\t Loss: 0.141485 \t Accuracy:0.199%\n",
      "Train Epoch: 21 [38400/60000 (64%)]\t Loss: 0.490207 \t Accuracy:0.198%\n",
      "Train Epoch: 21 [44800/60000 (75%)]\t Loss: 0.317040 \t Accuracy:0.198%\n",
      "Train Epoch: 21 [51200/60000 (85%)]\t Loss: 0.188206 \t Accuracy:0.198%\n",
      "Train Epoch: 21 [57600/60000 (96%)]\t Loss: 0.369903 \t Accuracy:0.198%\n",
      "Train Epoch: 22 [0/60000 (0%)]\t Loss: 0.363944 \t Accuracy:0.195%\n",
      "Train Epoch: 22 [6400/60000 (11%)]\t Loss: 0.297168 \t Accuracy:0.198%\n",
      "Train Epoch: 22 [12800/60000 (21%)]\t Loss: 0.234710 \t Accuracy:0.198%\n",
      "Train Epoch: 22 [19200/60000 (32%)]\t Loss: 0.182385 \t Accuracy:0.198%\n",
      "Train Epoch: 22 [25600/60000 (43%)]\t Loss: 0.224557 \t Accuracy:0.198%\n",
      "Train Epoch: 22 [32000/60000 (53%)]\t Loss: 0.231575 \t Accuracy:0.198%\n",
      "Train Epoch: 22 [38400/60000 (64%)]\t Loss: 0.184089 \t Accuracy:0.198%\n",
      "Train Epoch: 22 [44800/60000 (75%)]\t Loss: 0.197309 \t Accuracy:0.198%\n",
      "Train Epoch: 22 [51200/60000 (85%)]\t Loss: 0.191996 \t Accuracy:0.198%\n",
      "Train Epoch: 22 [57600/60000 (96%)]\t Loss: 0.156824 \t Accuracy:0.198%\n",
      "Train Epoch: 23 [0/60000 (0%)]\t Loss: 0.129800 \t Accuracy:0.203%\n",
      "Train Epoch: 23 [6400/60000 (11%)]\t Loss: 0.170364 \t Accuracy:0.198%\n",
      "Train Epoch: 23 [12800/60000 (21%)]\t Loss: 0.248294 \t Accuracy:0.199%\n",
      "Train Epoch: 23 [19200/60000 (32%)]\t Loss: 0.337460 \t Accuracy:0.199%\n",
      "Train Epoch: 23 [25600/60000 (43%)]\t Loss: 0.367971 \t Accuracy:0.199%\n",
      "Train Epoch: 23 [32000/60000 (53%)]\t Loss: 0.199487 \t Accuracy:0.199%\n",
      "Train Epoch: 23 [38400/60000 (64%)]\t Loss: 0.230479 \t Accuracy:0.198%\n",
      "Train Epoch: 23 [44800/60000 (75%)]\t Loss: 0.269302 \t Accuracy:0.198%\n",
      "Train Epoch: 23 [51200/60000 (85%)]\t Loss: 0.150443 \t Accuracy:0.198%\n",
      "Train Epoch: 23 [57600/60000 (96%)]\t Loss: 0.230888 \t Accuracy:0.198%\n",
      "Train Epoch: 24 [0/60000 (0%)]\t Loss: 0.166798 \t Accuracy:0.200%\n",
      "Train Epoch: 24 [6400/60000 (11%)]\t Loss: 0.281378 \t Accuracy:0.197%\n",
      "Train Epoch: 24 [12800/60000 (21%)]\t Loss: 0.416855 \t Accuracy:0.197%\n",
      "Train Epoch: 24 [19200/60000 (32%)]\t Loss: 0.262517 \t Accuracy:0.197%\n",
      "Train Epoch: 24 [25600/60000 (43%)]\t Loss: 0.170964 \t Accuracy:0.197%\n",
      "Train Epoch: 24 [32000/60000 (53%)]\t Loss: 0.375886 \t Accuracy:0.198%\n",
      "Train Epoch: 24 [38400/60000 (64%)]\t Loss: 0.356510 \t Accuracy:0.198%\n",
      "Train Epoch: 24 [44800/60000 (75%)]\t Loss: 0.310243 \t Accuracy:0.198%\n",
      "Train Epoch: 24 [51200/60000 (85%)]\t Loss: 0.158947 \t Accuracy:0.198%\n",
      "Train Epoch: 24 [57600/60000 (96%)]\t Loss: 0.137056 \t Accuracy:0.198%\n",
      "Train Epoch: 25 [0/60000 (0%)]\t Loss: 0.337477 \t Accuracy:0.203%\n",
      "Train Epoch: 25 [6400/60000 (11%)]\t Loss: 0.432665 \t Accuracy:0.198%\n",
      "Train Epoch: 25 [12800/60000 (21%)]\t Loss: 0.336180 \t Accuracy:0.198%\n",
      "Train Epoch: 25 [19200/60000 (32%)]\t Loss: 0.390464 \t Accuracy:0.198%\n",
      "Train Epoch: 25 [25600/60000 (43%)]\t Loss: 0.214016 \t Accuracy:0.198%\n",
      "Train Epoch: 25 [32000/60000 (53%)]\t Loss: 0.227523 \t Accuracy:0.198%\n",
      "Train Epoch: 25 [38400/60000 (64%)]\t Loss: 0.163643 \t Accuracy:0.198%\n",
      "Train Epoch: 25 [44800/60000 (75%)]\t Loss: 0.316062 \t Accuracy:0.198%\n",
      "Train Epoch: 25 [51200/60000 (85%)]\t Loss: 0.227845 \t Accuracy:0.198%\n",
      "Train Epoch: 25 [57600/60000 (96%)]\t Loss: 0.167096 \t Accuracy:0.198%\n",
      "Train Epoch: 26 [0/60000 (0%)]\t Loss: 0.184065 \t Accuracy:0.203%\n",
      "Train Epoch: 26 [6400/60000 (11%)]\t Loss: 0.255992 \t Accuracy:0.198%\n",
      "Train Epoch: 26 [12800/60000 (21%)]\t Loss: 0.284247 \t Accuracy:0.199%\n",
      "Train Epoch: 26 [19200/60000 (32%)]\t Loss: 0.124685 \t Accuracy:0.198%\n",
      "Train Epoch: 26 [25600/60000 (43%)]\t Loss: 0.301751 \t Accuracy:0.198%\n",
      "Train Epoch: 26 [32000/60000 (53%)]\t Loss: 0.244054 \t Accuracy:0.198%\n",
      "Train Epoch: 26 [38400/60000 (64%)]\t Loss: 0.182870 \t Accuracy:0.198%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
